<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Python on Saurav Maheshkar</title><link>https://sauravm.netlify.app/categories/python/</link><description>Recent content in Python on Saurav Maheshkar</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sat, 10 Apr 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://sauravm.netlify.app/categories/python/index.xml" rel="self" type="application/rss+xml"/><item><title>Introduction to Duck Typing and EAFP</title><link>https://sauravm.netlify.app/blog/duck-typing-eafp/</link><pubDate>Sat, 12 Dec 2020 00:00:00 +0000</pubDate><guid>https://sauravm.netlify.app/blog/duck-typing-eafp/</guid><description>Duck-Typing is a extremely useful programming style, which truly makes python awesome. It enables us to &amp;ldquo;ignore&amp;rdquo; the object type and rather just check if the object contains the function or not.
Famously referred in the python documentation as:
&amp;ldquo;If it looks like a duck and quacks like a duck, it must be a duck&amp;rdquo;
If the codebase is well defined, this allows for flexibility by allowing polymorphic substitution.</description></item><item><title>X Ray Image Analysis</title><link>https://sauravm.netlify.app/project/xray-image-analysis/</link><pubDate>Sat, 10 Apr 2021 00:00:00 +0000</pubDate><guid>https://sauravm.netlify.app/project/xray-image-analysis/</guid><description>In this project, I went over the entire pipeline of creating a Binary Image Classifier using Tensorflow. I covered, all aspects of the pipeline such as experimenting with different network architectures and comparing metrics, pruning and quantization of the model for faster inference and finally two methods of deploying such models. I trained a Convolutional Neural Network(Efficient Net) to recognize chest X-rays of people with pneumonia and then created a interactive web application.</description></item><item><title>Compressed DNNs Forget</title><link>https://sauravm.netlify.app/project/bias-compressed/</link><pubDate>Wed, 03 Mar 2021 00:00:00 +0000</pubDate><guid>https://sauravm.netlify.app/project/bias-compressed/</guid><description>Reproducibility Study Current state-of-the-art models are famously huge and over-parameterized––in fact, they contain way more parameters than the number of data points in the dataset. But in many ways, over-parameterization is behind the success of modern-day deep learning. Think about something like Switch Transformer having a trillion parameters or Vision Transformer-Huge having 632M parameters. These models require enormous amounts of computation and memory and that not only increases the infrastructure costs, but also makes deployment to resource-constrained environments such as mobile phones or smart devices challenging.</description></item></channel></rss>